{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43961b1d",
   "metadata": {},
   "source": [
    "# Loós András Péter OXNGC0 : Projekt Graduation 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c46a89",
   "metadata": {},
   "source": [
    "## A Projekt célja:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba6f140",
   "metadata": {},
   "source": [
    "Az elmúlt hetekben West úr politikailag nem helyes szólásai miatt szeretném átélni újra a régi szép időket, ezért a Graduation című albumának mintájára generálunk egy új számot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7330a9",
   "metadata": {},
   "source": [
    "#### Használt csomagok:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6176cbe4",
   "metadata": {},
   "source": [
    "Numpy: matematikai függvénykönyvtár, többdimenziós tömbök és mátrixok használatára van\n",
    "\n",
    "Tensorflow: Gépi tanulás és mesterséges intelligencia eszköz, a szöveg értelmezésére használjuk\n",
    "\n",
    "Tqdm: Folyamat vizualizációs eszköz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e15d1b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tqdm\n",
    "#pip install tensorflow\n",
    "#pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206727c5",
   "metadata": {},
   "source": [
    "##### beolvassuk a szöveget és kisbetüssé tesszük."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a559b608",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Graduation.txt\", \"r\", encoding=\"utf8\") as lyrics:\n",
    "    script = lyrics.read().lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6c7fb7",
   "metadata": {},
   "source": [
    "##### kigyűjtjük a használt karaktereket a szövegből"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "747d37f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11789/11789 [00:00<00:00, 2357296.43it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11789"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "maxlen = 60\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "\n",
    "for i in tqdm(range(0, len(script) - maxlen, step)):\n",
    "    sentences.append(script[i: i + maxlen])\n",
    "    next_chars.append(script[i + maxlen])\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477afa2f",
   "metadata": {},
   "source": [
    "##### a használt karaktereket és indexeiket eltároljuk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75901ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(script)))\n",
    "char_indices = dict((char, chars.index(char)) for char in chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10a1d0bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11789it [00:00, 92080.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x (11789, 60, 45)\n",
      "y (11789, 45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool_)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool_)\n",
    "for i, sentence in tqdm(enumerate(sentences)):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "\n",
    "print(\"x\", x.shape)\n",
    "print(\"y\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4124c9e",
   "metadata": {},
   "source": [
    "##### elkezdjük a modell betanítását"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301e2293",
   "metadata": {},
   "source": [
    "25 epochot használok. Lehet hogy sok, de hátha értelmesebb lesz tőle a szöveg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d7ed685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru (GRU)                   (None, 16)                3024      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 45)                765       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,789\n",
      "Trainable params: 3,789\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.GRU(16, input_shape=(maxlen, len(chars))),\n",
    "    tf.keras.layers.Dense(units=len(chars), activation='softmax')\n",
    "]) \n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.01))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2cde940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "93/93 [==============================] - 2s 9ms/step - loss: 2.9847\n",
      "Epoch 2/25\n",
      "93/93 [==============================] - 1s 9ms/step - loss: 2.5105\n",
      "Epoch 3/25\n",
      "93/93 [==============================] - 1s 9ms/step - loss: 2.3426\n",
      "Epoch 4/25\n",
      "93/93 [==============================] - 1s 9ms/step - loss: 2.2365\n",
      "Epoch 5/25\n",
      "93/93 [==============================] - 1s 9ms/step - loss: 2.1660\n",
      "Epoch 6/25\n",
      "93/93 [==============================] - 1s 9ms/step - loss: 2.1131\n",
      "Epoch 7/25\n",
      "93/93 [==============================] - 1s 9ms/step - loss: 2.0639\n",
      "Epoch 8/25\n",
      "93/93 [==============================] - 1s 9ms/step - loss: 2.0252\n",
      "Epoch 9/25\n",
      "93/93 [==============================] - 1s 9ms/step - loss: 1.9941\n",
      "Epoch 10/25\n",
      "93/93 [==============================] - 1s 9ms/step - loss: 1.9628\n",
      "Epoch 11/25\n",
      "93/93 [==============================] - 1s 9ms/step - loss: 1.9412\n",
      "Epoch 12/25\n",
      "93/93 [==============================] - 1s 9ms/step - loss: 1.9252\n",
      "Epoch 13/25\n",
      "93/93 [==============================] - 1s 9ms/step - loss: 1.9044\n",
      "Epoch 14/25\n",
      "93/93 [==============================] - 1s 9ms/step - loss: 1.8875\n",
      "Epoch 15/25\n",
      "93/93 [==============================] - 1s 9ms/step - loss: 1.8764\n",
      "Epoch 16/25\n",
      "93/93 [==============================] - 1s 9ms/step - loss: 1.8578\n",
      "Epoch 17/25\n",
      "93/93 [==============================] - 1s 9ms/step - loss: 1.8469\n",
      "Epoch 18/25\n",
      "93/93 [==============================] - 1s 9ms/step - loss: 1.8398\n",
      "Epoch 19/25\n",
      "93/93 [==============================] - 1s 9ms/step - loss: 1.8309\n",
      "Epoch 20/25\n",
      "93/93 [==============================] - 1s 9ms/step - loss: 1.8237\n",
      "Epoch 21/25\n",
      "93/93 [==============================] - 1s 9ms/step - loss: 1.8096\n",
      "Epoch 22/25\n",
      "93/93 [==============================] - 1s 9ms/step - loss: 1.8050\n",
      "Epoch 23/25\n",
      "93/93 [==============================] - 1s 9ms/step - loss: 1.7991\n",
      "Epoch 24/25\n",
      "93/93 [==============================] - 1s 9ms/step - loss: 1.7899\n",
      "Epoch 25/25\n",
      "93/93 [==============================] - 1s 9ms/step - loss: 1.7910\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/CPU:0\"):\n",
    "    model.fit(x, \n",
    "            y,\n",
    "            batch_size=128,\n",
    "            epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbffff7",
   "metadata": {},
   "source": [
    "##### fogunk egy véletlen sort. minden próba ezzel fog kezdeni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6f7ddf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tand there in a speedo\\nand be looked at like a fucking hero\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "start_index = random.randint(0, len(script) - maxlen - 1)\n",
    "base_text = script[start_index: start_index + maxlen]\n",
    "base_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4580373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426bdd5f",
   "metadata": {},
   "source": [
    "##### kiírjuk a szöveget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cd4f7a",
   "metadata": {},
   "source": [
    "megadjuk a generált szöveg hosszúságát, és hogy mennyire legyen magabiztos a modell\n",
    "\n",
    "a 0.1 és 0.2 inkább vizualizációnak van ott, ha túl szorosan követi a gép a betanult szöveget akkor nem lesz értelmes annyira az eredmény."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c9d20b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temp:  0.1\n",
      "tand there in a speedo\n",
      "and be looked at like a fucking hero\n",
      "\n",
      "i shin't the shin't the shin't the shin't the shin't the shin't the that the i shind i shin't the so shin't the shin't the to i shing the shin't the shind the shind i shind i shin't the shin't the shin't the shong the i shin't the shin't the shind i cand i shind i shing the shon't the shin't the shin't the shin't the shin't the i shin't the shin't the here the i shin't the shin't the shin't the sh\n",
      "Temp:  0.2\n",
      "tand there in a speedo\n",
      "and be looked at like a fucking hero\n",
      "\n",
      "we her i'm i but the shon't the i so i shin't the to i shin't the now i'm in the shin't i'm and the i was the shong the i'm i can't the good to i can't the here the that the that the the here the i was the shin't the shind the to i shin't the i so stornger\n",
      "you her hood the shin't the that the i'm in the the win't whet the hat to and i can't the the i shind i'm never in the gon't the shong the whet\n",
      "Temp:  0.5\n",
      "tand there in a speedo\n",
      "and be looked at like a fucking hero\n",
      "\n",
      "i soun you ne dat the tronger\n",
      "(wand that i conde to i hour and up sot the bort the i hear hour where to it to i can't it ho aling't got i son the thing i so now whan't the the it than it to the sey shong to that gouh)\n",
      "(how i can the can the i was i good notiss\n",
      "in the can't in the your i shind now i like me shing to you\n",
      "big it me be tory i to on you i that fin me more like me mun thing i'm and i sa\n",
      "Temp:  1.0\n",
      "tand there in a speedo\n",
      "and be looked at like a fucking hero\n",
      "\n",
      "need aid's it the wy on, gat faster)\n",
      "home cors in to nem come\n",
      "now\n",
      "\".yoh, you fare the panem ha)\n",
      "won's my dive th thate ovea thay bay withnigg somit dows whet\n",
      "get brother\n",
      "neve\n",
      "now your yih) very gip, whtore i eyant the your fass\n",
      "sounger ween eps the but tang setbat\n",
      "now'ts, he hesed ttaandor is it on fbele i'lls whind that tanding ho jun got lidh\n",
      "do becas ever and gove to no hot mas tonenne, so on m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "temperatures = [0.1, 0.2, 0.5, 1.0]\n",
    "generated_characters = 400\n",
    "\n",
    "for temp in temperatures:\n",
    "    print(\"Temp: \", temp)\n",
    "    generated_text = base_text\n",
    "    print(generated_text)\n",
    "    for i in range(generated_characters):\n",
    "        sampled = np.zeros((1, maxlen, len(chars)))    \n",
    "        for t, char in enumerate(generated_text):\n",
    "            sampled[0, t, char_indices[char]] = 1.          \n",
    "        \n",
    "        preds = model.predict(sampled, verbose=0)[0]      \n",
    "        \n",
    "        next_index = sample(preds, temp)\n",
    "        next_char = chars[next_index]\n",
    "\n",
    "        generated_text += next_char\n",
    "        generated_text = generated_text[1:]\n",
    "\n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
